package dag1.gemini;

import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Queue;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentLinkedQueue;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.ExecutorCompletionService;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.Future;
import java.util.concurrent.atomic.AtomicInteger;

/**
 * æ”¹è¿›ç‚¹æ€»ç»“
 * æ•ˆç‡æå‡ (Efficiency)
 * æ ¸å¿ƒå˜æ›´ï¼šç”¨ ExecutorCompletionService æ›¿æ¢äº†æ‰‹åŠ¨çš„ Future è½®è¯¢ã€‚
 * æ•ˆæœï¼šä¸»çº¿ç¨‹ä¸å†å¿™ç­‰å¾…ï¼Œè€Œæ˜¯é€šè¿‡ completionService.take() é«˜æ•ˆåœ°é˜»å¡ï¼Œç›´åˆ°æœ‰ä»»åŠ¡å®Œæˆã€‚è¿™æå¤§åœ°é™ä½äº†CPUæ¶ˆè€—ï¼Œæ˜¯æ€§èƒ½ä¸Šçš„å…³é”®ä¼˜åŒ–ã€‚
 *
 * å¥å£®æ€§ä¸çº¿ç¨‹å®‰å…¨ (Robustness & Thread Safety)
 * æ ¸å¿ƒå˜æ›´ï¼šå°† inDegree çš„ Integer æ›¿æ¢ä¸º AtomicIntegerï¼Œå¹¶å°† HashMap æ›¿æ¢ä¸º ConcurrentHashMapã€‚
 * æ•ˆæœï¼šç¡®ä¿äº†åœ¨å¹¶å‘ç¯å¢ƒä¸‹å¯¹å›¾ç»“æ„ï¼ˆç‰¹åˆ«æ˜¯å…¥åº¦ï¼‰çš„ä¿®æ”¹æ˜¯åŸå­å’Œçº¿ç¨‹å®‰å…¨çš„ï¼Œé¿å…äº†æ½œåœ¨çš„æ•°æ®ç«äº‰ã€‚
 *
 * å®¹é”™æ€§ (Fault Tolerance)
 * æ ¸å¿ƒå˜æ›´ï¼šåœ¨ catch (ExecutionException e) å—ä¸­å¢åŠ äº†é‡è¯•é€»è¾‘ã€‚
 * æ•ˆæœï¼šå½“ä¸€ä¸ªä»»åŠ¡å¤±è´¥æ—¶ï¼Œå¼•æ“ä¼šå°è¯•é‡æ–°æäº¤å®ƒï¼ˆæœ€å¤š MAX_RETRIES æ¬¡ï¼‰ã€‚è¿™ä½¿å¾—å·¥ä½œæµèƒ½å¤Ÿä»ç¬æ—¶æ•…éšœï¼ˆå¦‚ç½‘ç»œæŠ–åŠ¨ã€æ•°æ®åº“ä¸´æ—¶ä¸å¯ç”¨ï¼‰ä¸­è‡ªåŠ¨æ¢å¤ã€‚main å‡½æ•°ä¸­çš„ç¤ºä¾‹ä¹Ÿæ¼”ç¤ºäº†å¦‚ä½•åˆ›å»ºä¸€ä¸ªåªå¤±è´¥ä¸€æ¬¡çš„èŠ‚ç‚¹æ¥æµ‹è¯•æ­¤åŠŸèƒ½ã€‚
 *
 * é”™è¯¯æ£€æµ‹ (Error Detection)
 * æ ¸å¿ƒå˜æ›´ï¼šåœ¨æ‰§è¡Œç»“æŸåï¼Œæ¯”è¾ƒ completedTasks çš„æ•°é‡å’Œæ€»èŠ‚ç‚¹æ•° nodes.size()ã€‚
 * æ•ˆæœï¼šå¦‚æœä¸¤è€…ä¸ç›¸ç­‰ï¼Œå°±å¯ä»¥æ–­å®šå·¥ä½œæµä¸­å­˜åœ¨å¾ªç¯ä¾èµ–æˆ–æ— æ³•æ¢å¤çš„ä»»åŠ¡å¤±è´¥ï¼Œå¹¶å‘ç”¨æˆ·æŠ¥å‘Šé”™è¯¯ï¼Œè€Œä¸æ˜¯é™é»˜ç»“æŸã€‚
 *
 * ä»£ç æ¸…æ™°åº¦ (Code Clarity)
 * æ ¸å¿ƒå˜æ›´ï¼šå°† Callable åŒ…è£…èµ·æ¥ï¼Œä½¿å…¶åœ¨å®Œæˆåèƒ½è¿”å›è‡ªèº«çš„ nodeIdã€‚è¿™ç®€åŒ–äº†ä» Future åå‘æŸ¥æ‰¾æ˜¯å“ªä¸ªä»»åŠ¡å®Œæˆçš„é€»è¾‘ã€‚
 * æ•ˆæœï¼šæ‰§è¡Œé€»è¾‘æ›´æµç•…ï¼Œæ›´å®¹æ˜“ç†è§£å’Œç»´æŠ¤ã€‚
 */
public class DAGExecutor {
    // ä½¿ç”¨çº¿ç¨‹å®‰å…¨çš„é›†åˆ
    private final Map<String, WorkflowNode> nodes = new ConcurrentHashMap<>();
    private final Map<String, List<String>> adjacencyList = new ConcurrentHashMap<>();
    private final Map<String, AtomicInteger> inDegree = new ConcurrentHashMap<>();

    // ç”¨äºé‡è¯•
    private final Map<String, Integer> retryCounts = new ConcurrentHashMap<>();
    private static final int MAX_RETRIES = 2;

    public void addNode(WorkflowNode node) {
        nodes.put(node.getId(), node);
        adjacencyList.put(node.getId(), new ArrayList<>());
        inDegree.put(node.getId(), new AtomicInteger(0));
    }

    public void addDependency(String from, String to) {
        adjacencyList.get(from).add(to);
        inDegree.get(to).incrementAndGet(); // åŸå­æ“ä½œ
    }

    public void executeWorkflow() throws InterruptedException {
        System.out.println("ğŸš€ Starting DAG workflow execution...");
        ExecutorService executor = Executors.newFixedThreadPool(Runtime.getRuntime().availableProcessors());
        // ExecutorCompletionService ä¼˜é›…åœ°å¤„ç†å·²å®Œæˆçš„ä»»åŠ¡ï¼Œé¿å…å¿™ç­‰å¾…
        ExecutorCompletionService<String> completionService = new ExecutorCompletionService<>(executor);

        Queue<String> readyQueue = new ConcurrentLinkedQueue<>();

        // 1. åˆå§‹åŒ–å°±ç»ªé˜Ÿåˆ—
        inDegree.forEach((nodeId, degree) -> {
            if (degree.get() == 0) {
                readyQueue.offer(nodeId);
            }
        });

        int submittedTasks = 0;
        int completedTasks = 0;
        Map<String, Future<String>> runningFutures = new HashMap<>();

        // æäº¤ç¬¬ä¸€æ‰¹ä»»åŠ¡
        while (!readyQueue.isEmpty()) {
            String nodeId = readyQueue.poll();
            submitTask(nodeId, completionService, runningFutures);
            submittedTasks++;
        }

        // 2. ä¸»å¾ªç¯ï¼šç­‰å¾…ä»»åŠ¡å®Œæˆï¼Œå¹¶è§¦å‘æ–°ä»»åŠ¡
        while (completedTasks < nodes.size()) {
            // take() æ–¹æ³•ä¼šé˜»å¡ï¼Œç›´åˆ°æœ‰ä»»åŠ¡å®Œæˆï¼Œéå¸¸é«˜æ•ˆ
            Future<String> completedFuture = completionService.take();
            if (completedFuture == null) {
                // å¦‚æœæ‰€æœ‰ä»»åŠ¡éƒ½å·²æäº¤ä¸”æ²¡æœ‰ä»»åŠ¡åœ¨è¿è¡Œï¼Œä½†æœªå…¨éƒ¨å®Œæˆï¼Œè¯´æ˜æœ‰å¾ªç¯
                break;
            }

            completedTasks++;
            String finishedNodeId = null;

            try {
                finishedNodeId = completedFuture.get();
                System.out.println("âœ… Task " + finishedNodeId + " completed successfully.");
                runningFutures.remove(finishedNodeId);

                // è§¦å‘åç»­ä»»åŠ¡
                List<String> dependents = adjacencyList.getOrDefault(finishedNodeId, new ArrayList<>());
                for (String dependentId : dependents) {
                    // å…¥åº¦å‡1ï¼Œå¦‚æœä¸º0åˆ™åŠ å…¥å°±ç»ªé˜Ÿåˆ—
                    if (inDegree.get(dependentId).decrementAndGet() == 0) {
                        readyQueue.offer(dependentId);
                    }
                }

            } catch (ExecutionException e) {
                // 3. å®¹é”™ä¸é‡è¯•é€»è¾‘
                finishedNodeId = findNodeIdByFuture(runningFutures, completedFuture);
                if (finishedNodeId != null) {
                    runningFutures.remove(finishedNodeId);
                    int currentRetries = retryCounts.getOrDefault(finishedNodeId, 0);
                    if (currentRetries < MAX_RETRIES) {
                        retryCounts.put(finishedNodeId, currentRetries + 1);
                        System.err.println("ğŸ”¥ Task " + finishedNodeId + " failed. Retrying (" + (currentRetries + 1) + "/" + MAX_RETRIES + ")...");
                        submitTask(finishedNodeId, completionService, runningFutures); // é‡æ–°æäº¤
                        completedTasks--; // å› ä¸ºé‡è¯•ï¼Œæ‰€ä»¥ä¸ç®—ä½œå®Œæˆ
                    } else {
                        System.err.println("ğŸ’€ Task " + finishedNodeId + " failed after " + MAX_RETRIES + " retries. Aborting workflow for this path.");
                        // åœ¨æ­¤å¯ä»¥å®ç°æ›´å¤æ‚çš„å¤±è´¥ç­–ç•¥ï¼Œå¦‚ä¸­æ–­æ•´ä¸ªå·¥ä½œæµ
                    }
                }
            }

            // æäº¤æ–°åŠ å…¥å°±ç»ªé˜Ÿåˆ—çš„ä»»åŠ¡
            while(!readyQueue.isEmpty()){
                String nodeId = readyQueue.poll();
                submitTask(nodeId, completionService, runningFutures);
                submittedTasks++;
            }
        }

        // 4. å¾ªç¯ä¾èµ–æ£€æµ‹
        if (completedTasks < nodes.size()) {
            System.err.println("ğŸ›‘ Workflow finished prematurely. Possible circular dependency detected or unrecoverable task failure.");
            System.err.println("Total Nodes: " + nodes.size() + ", Completed Nodes: " + completedTasks);
        } else {
            System.out.println("ğŸ‰ DAG workflow execution completed successfully.");
        }

        executor.shutdown();
    }

    private void submitTask(String nodeId, ExecutorCompletionService<String> cs, Map<String, Future<String>> futures) {
        WorkflowNode node = nodes.get(nodeId);
        // åŒ…è£… Callableï¼Œä½¿å…¶è¿”å› nodeId
        Future<String> future = cs.submit(() -> {
            node.call();
            return nodeId;
        });
        futures.put(nodeId, future);
        System.out.println("ğŸ“¨ Submitting task: " + nodeId);
    }

    private String findNodeIdByFuture(Map<String, Future<String>> futures, Future<String> future) {
        return futures.entrySet().stream()
                .filter(entry -> entry.getValue().equals(future))
                .map(Map.Entry::getKey)
                .findFirst()
                .orElse(null);
    }

    public static void main(String[] args) throws InterruptedException {
        DAGExecutor executor = new DAGExecutor();

        // åˆ›å»ºä¸€ä¸ªæ›´å¤æ‚çš„å›¾ï¼ŒåŒ…å«å¹¶è¡Œåˆ†æ”¯å’Œå¯èƒ½å¤±è´¥çš„èŠ‚ç‚¹
        //      1
        //     / \
        //    2   3 (fails once)
        //    |   |
        //    4   5
        //     \ /
        //      6
        WorkflowNode node1 = new WorkflowNode("1", "Start");
        WorkflowNode node2 = new WorkflowNode("2", "Process A");
        WorkflowNode node3 = new WorkflowNode("3", "Process B (will fail)", true); // è¿™ä¸ªèŠ‚ç‚¹ä¼šå¤±è´¥
        WorkflowNode node4 = new WorkflowNode("4", "Process C");
        WorkflowNode node5 = new WorkflowNode("5", "Process D");
        WorkflowNode node6 = new WorkflowNode("6", "End");

        executor.addNode(node1);
        executor.addNode(node2);
        executor.addNode(node3);
        executor.addNode(node4);
        executor.addNode(node5);
        executor.addNode(node6);

        executor.addDependency("1", "2");
        executor.addDependency("1", "3");
        executor.addDependency("2", "4");
        executor.addDependency("3", "5");
        executor.addDependency("4", "6");
        executor.addDependency("5", "6");

        // æ¨¡æ‹Ÿé‡è¯•æˆåŠŸåœºæ™¯
        // ä¿®æ”¹node3ï¼Œè®©å®ƒåœ¨ç¬¬ä¸€æ¬¡è°ƒç”¨æ—¶å¤±è´¥ï¼Œä¹‹åæˆåŠŸ
        WorkflowNode failingNode = new WorkflowNode("3", "Process B (will fail once)", true) {
            private final AtomicInteger attempts = new AtomicInteger(0);
            @Override
            public Boolean call() throws Exception {
                System.out.println("â–¶ï¸ Executing Node: " + "Process B" + " (Attempt " + (attempts.get() + 1) + ")");
                Thread.sleep(1000);
                if (attempts.getAndIncrement() == 0) { // ä»…ç¬¬ä¸€æ¬¡å¤±è´¥
                    System.out.println("âŒ Node " + "Process B" + " is failing on purpose.");
                    throw new RuntimeException("Simulated first failure");
                }
                System.out.println("âœ… Node " + "Process B" + " completed successfully on retry.");
                return true;
            }
        };
        executor.addNode(failingNode); // è¦†ç›–ä¹‹å‰çš„node3

        executor.executeWorkflow();
    }
}